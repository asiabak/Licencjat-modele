{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9L_ZgXJ9o9i",
        "outputId": "9b7ad052-22cb-4a07-f5b6-b87859ac78ce",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Pobranie modelu\n",
        "model_url = \"https://huggingface.co/clarin-pl/word2vec-kgr10/resolve/main/skipgram.v300.m8.ns.mwe.w2v.gensim\"\n",
        "model_path = \"word2vec-kgr10.gensim\"\n",
        "\n",
        "# Pobranie pliku\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(model_url, model_path)\n",
        "\n",
        "# Download the vectors file separately\n",
        "vectors_url = \"https://huggingface.co/clarin-pl/word2vec-kgr10/resolve/main/skipgram.v300.m8.ns.mwe.w2v.gensim.vectors.npy\" # URL of the vectors file\n",
        "vectors_path = \"word2vec-kgr10.gensim.vectors.npy\" # Local path for the vectors file\n",
        "urllib.request.urlretrieve(vectors_url, vectors_path)\n",
        "\n",
        "# Załadowanie modelu\n",
        "model = KeyedVectors.load(model_path)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "gUxRKV1h-eGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "reviews = pd.read_csv(\"filmweb_jednolity_sentyment.csv\")\n",
        "reviews_with_idioms = pd.read_csv('filmweb_i_idiomy.csv')\n",
        "print(reviews.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8MO9wLN8eto",
        "outputId": "7deb1bf6-057c-4197-b107-5a2a2a79e7ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review  sentiment\n",
            "0  Nemo Nobody, bohater pierwszego od ponad dekad...          0\n",
            "1  \"Dziewczyna moich koszmarów\" zaczyna się w mom...          0\n",
            "2  Kultowy w pewnych kręgach horror Joe'ego D'Ama...          1\n",
            "3  Motyw znany i często eksploatowany przez kino:...          1\n",
            "4  Zwyczajna rozbita koreańska rodzina: rodzice r...          0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tutaj trzeba dodać text preprocessing"
      ],
      "metadata": {
        "id": "KGXhZ_019IeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Wczytanie listy polskich stop words z pliku\n",
        "# with open('polish.stopwords.txt', 'r', encoding='utf-8') as file:\n",
        "#     polish_stopwords = set(file.read().splitlines())\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Konwersja na małe litery\n",
        "    text = text.lower()\n",
        "\n",
        "    # Usunięcie znaków interpunkcyjnych\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenizacja\n",
        "    words = text.split()\n",
        "\n",
        "    # Usunięcie stop words\n",
        "    # words = [word for word in words if word not in polish_stopwords]\n",
        "\n",
        "    # Połączenie słów z powrotem w tekst\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Zastosowanie przetwarzania tekstu dla kolumny 'review'\n",
        "reviews['review_processed'] = reviews['review'].apply(preprocess_text)\n",
        "reviews_with_idioms['review_processed'] = reviews_with_idioms['review'].apply(preprocess_text)\n",
        "\n",
        "# Wyświetlenie przykładowych przetworzonych recenzji\n",
        "# print(\"Przykładowe przetworzone recenzje:\")\n",
        "# print(reviews[['review', 'review_processed']].head(2))\n",
        "\n",
        "# Aktualizacja funkcji wektoryzacji, aby używała przetworzonych recenzji\n",
        "def vectorize_review(text, model):\n",
        "    words = word_tokenize(text.lower())\n",
        "    words = [word for word in words if word in model.key_to_index]\n",
        "\n",
        "    if words:\n",
        "        return np.mean(model[words], axis=0)  # Średnia wektorów słów\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)  # Zerowy wektor, jeśli brak znanych słów\n",
        "\n",
        "# Aktualizacja wektorów dla przetworzonych recenzji\n",
        "reviews['vector'] = reviews['review_processed'].apply(lambda x: vectorize_review(x, model))\n",
        "reviews_with_idioms['vector'] = reviews_with_idioms['review_processed'].apply(lambda x: vectorize_review(x, model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jxna0__Bwn3",
        "outputId": "2b808141-8286-4afe-c61c-38e5b9c7147a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import nltk\n",
        "# nltk.download('punkt_tab')\n",
        "# from nltk.tokenize import word_tokenize\n",
        "\n",
        "# def vectorize_review(text, model):\n",
        "#     words = word_tokenize(text.lower())\n",
        "#     words = [word for word in words if word in model.key_to_index]\n",
        "\n",
        "#     if words:\n",
        "#         return np.mean(model[words], axis=0)  # Średnia wektorów słów\n",
        "#     else:\n",
        "#         return np.zeros(model.vector_size)  # Zerowy wektor, jeśli brak znanych słów\n",
        "\n",
        "# # Tworzenie wektorów dla wszystkich recenzji\n",
        "# reviews['vector'] = reviews['review_processed'].apply(lambda x: vectorize_review(x, model))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_2UWsK886sb",
        "outputId": "386843d6-b070-4e63-f1dc-38ef93cc5f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Przygotowanie danych\n",
        "X = np.vstack(reviews['vector'].values)\n",
        "y = reviews['sentiment'].values\n",
        "X2 = np.vstack(reviews_with_idioms['vector'].values)\n",
        "y2 = reviews_with_idioms['sentiment'].values\n",
        "\n",
        "# Podział na zbiory treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=None, random_state=12)\n",
        "\n",
        "# Trening modelu kNN\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X2_train, y2_train)\n",
        "\n",
        "# Predykcja i ocena\n",
        "y_pred = knn.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQs9bkKw9Toq",
        "outputId": "2f6b24ab-bfe9-42b2-9fd4-3037bdc2edd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.47      0.37      0.41       125\n",
            "           0       0.61      0.68      0.64       371\n",
            "           1       0.58      0.56      0.57       285\n",
            "\n",
            "    accuracy                           0.59       781\n",
            "   macro avg       0.56      0.54      0.54       781\n",
            "weighted avg       0.58      0.59      0.58       781\n",
            "\n"
          ]
        }
      ]
    }
  ]
}